{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "supervised_word_embeddings.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyONY4nc5CM5TLMA1Cijllwc",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Rahulraj31/NLP_files/blob/main/supervised_word_embeddings.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bk4gjGMmnMF7"
      },
      "source": [
        "<center><h1> Word embedding using keras embedding layer</h1></center>\n",
        "\n",
        "It is done in two ways supervised and semi- supervised (word2vec and glove). Here we will see supervised type of word embedding."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5y6Mb4pvnE7e"
      },
      "source": [
        " import numpy as np \n",
        " from tensorflow.keras.preprocessing.text import one_hot\n",
        " from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        " from tensorflow.keras.models import Sequential\n",
        "# from tensorflow.keras.layers import Dense,Flatten,Embedding\n",
        "from tensorflow.keras import layers"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mAlyLwKS2J8L"
      },
      "source": [
        "## We will work on food review"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-nKTr-LK043l"
      },
      "source": [
        "reviews =['nice food','amazing restaurant',\n",
        "          'too good','just loved it!',\n",
        "          'will go again', 'horrible food',\n",
        "          'never go there','poor service',\n",
        "          'poor quality','needs improvement']\n",
        "\n",
        "sentiment=np.array([1,1,1,1,1,0,0,0,0,0])       "
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AR3ZzFUy2MP7",
        "outputId": "bb084188-344a-4ca1-82da-e6180c7e8591"
      },
      "source": [
        "one_hot(\"amazing restaurant\",30) \n",
        "#(review, vocabulary size); returns position of words in review between 0 to vocabulary size "
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[10, 8]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vGp0D6La2sUG",
        "outputId": "460d9842-6720-4603-ee9c-ed91a436cf9b"
      },
      "source": [
        "# one_hot enconding all reviews \n",
        "vocab_size = 30 \n",
        "encoded_reviews = [one_hot(d,vocab_size) for d in reviews]\n",
        "encoded_reviews"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[[1, 23],\n",
              " [10, 8],\n",
              " [10, 11],\n",
              " [5, 13, 15],\n",
              " [5, 2, 1],\n",
              " [7, 23],\n",
              " [15, 2, 10],\n",
              " [10, 7],\n",
              " [10, 19],\n",
              " [7, 12]]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "phTn4xro3j98",
        "outputId": "4d18873c-8989-4ce7-d342-7b7ee3a51a1f"
      },
      "source": [
        "#using concept of padding i.e. all zeros after considering max length for a group of words in 1 iteration.\n",
        "max_length=3\n",
        "padded_reviews = pad_sequences(encoded_reviews,maxlen=max_length,padding=\"post\") #post means move towards end\n",
        "padded_reviews"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[ 1, 23,  0],\n",
              "       [10,  8,  0],\n",
              "       [10, 11,  0],\n",
              "       [ 5, 13, 15],\n",
              "       [ 5,  2,  1],\n",
              "       [ 7, 23,  0],\n",
              "       [15,  2, 10],\n",
              "       [10,  7,  0],\n",
              "       [10, 19,  0],\n",
              "       [ 7, 12,  0]], dtype=int32)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kgG75lz_4wAU"
      },
      "source": [
        "embeded_vector_size=4 \n",
        "\n",
        "model =Sequential([\n",
        "layers.Embedding(vocab_size,embeded_vector_size, input_length=max_length , \n",
        "          name = 'embedding'),\n",
        "layers.Flatten(),\n",
        "layers.Dense(1, activation='sigmoid')\n",
        "])"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aElI0o4I5EtV"
      },
      "source": [
        "X= padded_reviews\n",
        "y= sentiment \n"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "c4bfVRkwEaqs",
        "outputId": "de791486-421f-4251-80ad-76d13a320209"
      },
      "source": [
        "model.compile(optimizer=\"adam\",loss=\"binary_crossentropy\", metrics=['accuracy'])\n",
        "model.summary()"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "embedding (Embedding)        (None, 3, 4)              120       \n",
            "_________________________________________________________________\n",
            "flatten (Flatten)            (None, 12)                0         \n",
            "_________________________________________________________________\n",
            "dense (Dense)                (None, 1)                 13        \n",
            "=================================================================\n",
            "Total params: 133\n",
            "Trainable params: 133\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jHV4ZXvREsim",
        "outputId": "50a8b8d6-c7b6-4228-dd0a-9642d20f1c50"
      },
      "source": [
        "model.fit(X,y,epochs=50, verbose=0)"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7fa060062d90>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wpTvtzdDF6SN",
        "outputId": "5da42b3a-7451-4b0a-d77c-4c921260f8b1"
      },
      "source": [
        "loss, accuracy = model.evaluate(X,y)\n",
        "accuracy"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "1/1 [==============================] - 0s 107ms/step - loss: 0.6489 - accuracy: 0.9000\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.8999999761581421"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mre3h-1-HS2u",
        "outputId": "f97bd884-906a-41be-e36d-d85ad2c61fc7"
      },
      "source": [
        "model.get_layer('embedding').get_weights()"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[array([[-0.05152801,  0.00512335, -0.01779826, -0.09899331],\n",
              "        [ 0.04042148,  0.02375433, -0.04166621, -0.0528014 ],\n",
              "        [-0.06183644, -0.05524426, -0.01336385,  0.00690807],\n",
              "        [-0.03541169, -0.0163967 , -0.01136861,  0.00688152],\n",
              "        [-0.03581367, -0.04769589,  0.03186225, -0.00571904],\n",
              "        [ 0.02757694,  0.04548829, -0.02298105, -0.08979926],\n",
              "        [ 0.02345592,  0.00883148, -0.01890981, -0.01881847],\n",
              "        [-0.02542276, -0.06987578,  0.09695844,  0.03299649],\n",
              "        [-0.05567685, -0.05232996,  0.05352526, -0.00276814],\n",
              "        [ 0.03671655,  0.03641112,  0.00442088, -0.01583611],\n",
              "        [-0.06666774,  0.01730129, -0.04846934, -0.0618474 ],\n",
              "        [-0.08670742, -0.08060051,  0.04715146, -0.04182909],\n",
              "        [ 0.005611  ,  0.09653268, -0.07486653,  0.09271233],\n",
              "        [-0.0491286 , -0.08203936,  0.01104398, -0.05068713],\n",
              "        [-0.03432041, -0.02262044,  0.02986076,  0.0326782 ],\n",
              "        [-0.07352121, -0.08371338,  0.02594759,  0.00474807],\n",
              "        [ 0.01469436, -0.02709483, -0.03787986,  0.02554145],\n",
              "        [ 0.04832392,  0.03633832,  0.04722502, -0.00077351],\n",
              "        [-0.03520022,  0.01414892,  0.01779881, -0.04851359],\n",
              "        [ 0.10134418,  0.0185749 , -0.04703765,  0.03935168],\n",
              "        [ 0.00339214, -0.00731621, -0.02901868, -0.04510491],\n",
              "        [ 0.03350277,  0.04293888,  0.03492853, -0.02797925],\n",
              "        [-0.02337855, -0.02803865,  0.01046953, -0.04792359],\n",
              "        [-0.00217925, -0.02615433,  0.06084561, -0.02812957],\n",
              "        [-0.03569056, -0.02726948,  0.00081186, -0.03059247],\n",
              "        [-0.03375439, -0.01764572, -0.03420222,  0.03821189],\n",
              "        [-0.04405265, -0.0300044 ,  0.0292888 ,  0.04698629],\n",
              "        [ 0.0427379 , -0.03795124,  0.04761196,  0.04751762],\n",
              "        [-0.0149556 ,  0.04136422, -0.00772629,  0.04736539],\n",
              "        [-0.04731647, -0.02644867,  0.0346686 , -0.03375269]],\n",
              "       dtype=float32)]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "io2Sy1nbL9oJ"
      },
      "source": [
        "## Important Links\n",
        "\n",
        "**Tutorial Video**- https://www.youtube.com/watch?v=Fuw0wv3X-0o&list=PLeo1K3hjS3uu7CxAacxVndI4bE_o3BDtO&index=41&ab_channel=codebasics\n",
        "\n",
        "**Tutorial Article**-https://machinelearningmastery.com/use-word-embedding-layers-deep-learning-keras/"
      ]
    }
  ]
}